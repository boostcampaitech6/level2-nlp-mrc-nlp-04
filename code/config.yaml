meta_args:
  entity_name: "mrc-project"
  project_name: "Test"
  display_name: "001"

model_args:
  model_name_or_path: klue/bert-base
  config_name: null
  tokenizer_name: null

data_args:
  train_dataset_name: "../data/train_dataset"
  test_dataset_name: "../data/test_dataset"
  #curriculum_learning_prediction_file: "./models/train_eval_json/predictions.json"
  overwrite_cache: false
  preprocessing_num_workers: null
  max_seq_length: 384
  pad_to_max_length: false
  doc_stride: 128
  max_answer_length: 30
  eval_retrieval: true
  num_clusters: 64
  top_k_retrieval: 6
  use_faiss: false
  #sparse_embedding: "elasticsearch"
  #es_index: "wiki"

training_args:
  output_dir: "./models/model_name" #
  overwrite_output_dir: true
  do_train: true
  do_eval: false
  evaluation_strategy: "steps"
  eval_steps: 100
  logging_steps: 1
  save_strategy: "steps"
  save_steps: 100
  save_total_limit: 1
  load_best_model_at_end: true
  metric_for_best_model: "exact_match"
  per_device_train_batch_size: 16
  per_device_eval_batch_size: 16
  gradient_accumulation_steps: 1
  learning_rate: 5.0e-05
  num_train_epochs: 3
  max_steps: -1
  lr_scheduler_type: "cosine_with_restarts"
  warmup_ratio: 0.1
  # warmup_steps: 300
  seed: 42
  fp16: true
  optim: "adamw_hf"
  report_to: ["wandb"]
  early_stopping: 5
inference_args:
  output_dir: "./outputs/output_name"
  overwrite_output_dir: false
  do_eval: true
  do_predict: false
  report_to: ["wandb"]